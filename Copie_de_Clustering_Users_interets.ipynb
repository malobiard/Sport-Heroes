{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import des modules"
      ],
      "metadata": {
        "id": "4S2p9jZzHWIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "bZcojexRHUhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import des fichiers"
      ],
      "metadata": {
        "id": "q7pa6-v3IcLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"/content/Clustering-Users-interets - Sheet13.csv\")\n",
        "df0.set_index(\"utilisateur\", inplace = True)\n",
        "\n",
        "df1 = df0[['distance_moyenne_running_hebdo_last_3months','vitesse_running_mediane','sorties_running_mois']]\n",
        "\n",
        "df1bis = df1.copy()\n",
        "df1bis.drop('sorties_running_mois', axis=1, inplace=True)\n",
        "df1bis = df1bis.loc[df1bis['distance_moyenne_running_hebdo_last_3months'] > 0]\n",
        "df1bis = df1bis.loc[df1bis['vitesse_running_mediane'] > 0]\n",
        "df1bis = df1bis.loc[df1bis['vitesse_running_mediane'] <= 11]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df1_standard = scaler.fit_transform(df1bis)\n",
        "df1_standard = pd.DataFrame(df1_standard, index= df1bis.index, columns=df1bis.columns)\n",
        "\n",
        "\n",
        "df2 = df0[['distance_moyenne_cycling_hebdo_last_3months','vitesse_cycling_mediane','sorties_cycling_mois']]\n",
        "\n",
        "df2bis = df2.copy()\n",
        "df2bis.drop('sorties_cycling_mois', axis=1, inplace=True)\n",
        "df2bis = df2bis.loc[df2bis['distance_mediane_cycling_hebdo_last_3months'] > 0]\n",
        "df2bis = df2bis.loc[df2bis['vitesse_cycling_mediane'] > 0]\n",
        "df2bis = df2bis.loc[df2bis['vitesse_cycling_mediane'] <= 8]\n",
        "\n",
        "df2_standard = scaler.fit_transform(df2bis)\n",
        "df2_standard = pd.DataFrame(df2_standard, index= df2bis.index, columns=df2bis.columns)\n",
        "\n",
        "\n",
        "df3 = df0[['distance_moyenne_swimming_hebdo_last_3months','vitesse_swimming_mediane','sorties_swimming_mois']]\n",
        "\n",
        "df3bis = df3.copy()\n",
        "df3bis.drop('sorties_swimming_mois', axis=1, inplace=True)\n",
        "df3bis = df3bis.loc[df3bis['distance_moyenne_swimming_hebdo_last_3months'] > 0]\n",
        "df3bis = df3bis.loc[df3bis['vitesse_swimming_mediane'] > 0]\n",
        "df3bis = df3bis.loc[df3bis['vitesse_swimming_mediane'] <= 100]\n",
        "\n",
        "df3_standard = scaler.fit_transform(df3bis)\n",
        "df3_standard = pd.DataFrame(df3_standard, index= df3bis.index, columns=df3bis.columns)\n",
        "\n",
        "\n",
        "df4 = df0[['distance_moyenne_walking_hebdo_last_3months','vitesse_walking_mediane','sorties_walking_mois']]\n",
        "\n",
        "df4bis = df4.copy()\n",
        "df4bis.drop('sorties_walking_mois', axis=1, inplace=True)\n",
        "df4bis = df4bis.loc[df4bis['distance_moyenne_walking_hebdo_last_3months'] > 0]\n",
        "df4bis = df4bis.loc[df4bis['vitesse_walking_mediane'] > 0]\n",
        "df4bis = df4bis.loc[df4bis['vitesse_walking_mediane'] <= 26]\n",
        "\n",
        "df4_standard = scaler.fit_transform(df4bis)\n",
        "df4_standard = pd.DataFrame(df4_standard, index= df4bis.index, columns=df4bis.columns)\n",
        "\n",
        "\n",
        "df5 = df0[['nombre_sessions_yoga_hebdo_last_3months','duree_yoga_moyenne']]\n",
        "\n",
        "df5bis = df5.copy()\n",
        "df5bis = df5bis.loc[df5bis['nombre_sessions_yoga_hebdo_last_3months'] > 0]\n",
        "df5bis = df5bis.loc[df5bis['duree_yoga_moyenne'] > 0]\n",
        "\n",
        "df5_standard = scaler.fit_transform(df5bis)\n",
        "df5_standard = pd.DataFrame(df5_standard, index= df5bis.index, columns=df5bis.columns)\n",
        "\n",
        "\n",
        "df6 = df0[['nombre_sessions_workout_hebdo_last_3months','duree_workout_moyenne']]\n",
        "\n",
        "df6bis = df6.copy()\n",
        "df6bis = df6bis.loc[df6bis['nombre_sessions_workout_hebdo_last_3months'] > 0]\n",
        "df6bis = df6bis.loc[df6bis['duree_workout_moyenne'] > 0]\n",
        "\n",
        "df6_standard = scaler.fit_transform(df6bis)\n",
        "df6_standard = pd.DataFrame(df6_standard, index= df6bis.index, columns=df6bis.columns)"
      ],
      "metadata": {
        "id": "oR3UhKLtPukx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering global, sur toutes les colonnes en même temps"
      ],
      "metadata": {
        "id": "S7XpFNyvHaXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Running"
      ],
      "metadata": {
        "id": "hEy85w3mHrWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df1_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LZDLiw5oHrx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Running"
      ],
      "metadata": {
        "id": "IOFEGRNRoPZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df1_standard.columns[0],df1_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df1_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df1_standard[\"running_cluster\"] = kmeans.labels_\n",
        "df1bis[\"running_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df1.head()\n",
        "stats = df1bis.groupby('running_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df1bis['running_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "QDNgHpI1oPtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Cycling"
      ],
      "metadata": {
        "id": "Gna93i0Boj8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df2_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SGW9R4GsokH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Cycling"
      ],
      "metadata": {
        "id": "excIhgxZokYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df2_standard.columns[0],df2_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df2_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df2_standard[\"cycling_cluster\"] = kmeans.labels_\n",
        "df2bis[\"cycling_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df2_standard.head()\n",
        "stats = df2_standard.groupby('cycling_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df2_standard['cycling_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "XNxa2O-iokjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Swimming"
      ],
      "metadata": {
        "id": "8Dx06rXyokqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df3_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DcO5Hdnrokx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Swimming"
      ],
      "metadata": {
        "id": "sgOtE0bpok5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df3_standard.columns[0],df3_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df3_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df3_standard[\"swimming_cluster\"] = kmeans.labels_\n",
        "df3bis[\"swimming_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df3_standard.head()\n",
        "stats = df3_standard.groupby('swimming_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df3_standard['swimming_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "eRoLG-lhok_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Walking"
      ],
      "metadata": {
        "id": "DSbRpixPolFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df4_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V7VLcsnVolMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Walking"
      ],
      "metadata": {
        "id": "Cd84xOlxolSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df4_standard.columns[0],df4_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df4_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df4_standard[\"walking_cluster\"] = kmeans.labels_\n",
        "df4bis[\"walking_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df4_standard.head()\n",
        "stats = df4_standard.groupby('walking_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df4_standard['walking_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "pzoa43-HolZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Yoga"
      ],
      "metadata": {
        "id": "bg-6ZgVIold7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df5_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dvXBKI4qoljl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Yoga"
      ],
      "metadata": {
        "id": "8YeVRnrEo4v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df5_standard.columns[0],df5_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df5_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df5_standard[\"yoga_cluster\"] = kmeans.labels_\n",
        "df5bis[\"yoga_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df5_standard.head()\n",
        "stats = df5_standard.groupby('yoga_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df5_standard['yoga_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "VsOnObuDo438"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude : Workout"
      ],
      "metadata": {
        "id": "BhgafqTPo4-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = df6_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bR7O5eUvo5FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering : Workout"
      ],
      "metadata": {
        "id": "abWdwnkUo5NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 3\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [df6_standard.columns[0],df6_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = df6_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "df6_standard[\"workout_cluster\"] = kmeans.labels_\n",
        "df6bis[\"workout_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df6_standard.head()\n",
        "stats = df6_standard.groupby('workout_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "stats\n",
        "comptage = df6_standard['workout_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "KqJR_MCko5UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = df6bis.groupby('workout_cluster').agg(['mean'])\n",
        "stats"
      ],
      "metadata": {
        "id": "gz8-2nCAjxEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_tot)"
      ],
      "metadata": {
        "id": "bZqkh4zs0Won"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export de tous les tableaux en CSV"
      ],
      "metadata": {
        "id": "NGFACDEx7B82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''df1_standard.to_csv('data_running_cluster.csv', index=True)\n",
        "df2_standard.to_csv('data_cycling_cluster.csv', index=True)\n",
        "f3_standard.to_csv('data_swimming_cluster.csv', index=True)\n",
        "df4_standard.to_csv('data_walking_cluster.csv', index=True)\n",
        "df5_standard.to_csv('data_yoga_cluster.csv', index=True)\n",
        "df6_standard.to_csv('data_workout_cluster.csv', index=True)\n",
        "df1bis.to_csv('running_cluster.csv', index=True)\n",
        "df2bis.to_csv('cycling_cluster.csv', index=True)\n",
        "df3bis.to_csv('swimming_cluster.csv', index=True)\n",
        "df4bis.to_csv('walking_cluster.csv', index=True)\n",
        "df5bis.to_csv('yoga_cluster.csv', index=True)\n",
        "df6bis.to_csv('workout_cluster.csv', index=True)\n",
        "files.download('running_cluster.csv')\n",
        "files.download('cycling_cluster.csv')\n",
        "files.download('swimming_cluster.csv')\n",
        "files.download('walking_cluster.csv')\n",
        "files.download('yoga_cluster.csv')\n",
        "files.download('workout_cluster.csv')'''\n",
        "\n",
        "df_tot = pd.merge(df1bis[['running_cluster']], df2bis[['cycling_cluster']], on='utilisateur', how='outer')\n",
        "df_tot = pd.merge(df_tot, df3bis[['swimming_cluster']], on='utilisateur', how='outer')\n",
        "df_tot = pd.merge(df_tot, df4bis[['walking_cluster']], on='utilisateur', how='outer')\n",
        "df_tot = pd.merge(df_tot, df5bis[['yoga_cluster']], on='utilisateur', how='outer')\n",
        "df_tot = pd.merge(df_tot, df6bis[['workout_cluster']], on='utilisateur', how='outer')\n",
        "\n",
        "df_tot = df_tot.fillna('null')\n",
        "\n",
        "df_tot.to_csv('df_tot.csv', index=True)\n",
        "files.download('df_tot.csv')"
      ],
      "metadata": {
        "id": "u0ENa1Z37CIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import du fichier avec les clusters pour chaque sport\n"
      ],
      "metadata": {
        "id": "YQQXnPJjhOEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dftot = pd.read_csv(\"/content/cluster_chaque_sport sans sorties par mois - data totale.csv\")\n",
        "dftot.set_index(\"utilisateur\", inplace = True)\n",
        "dftotbis = dftot.copy()\n",
        "scaler = StandardScaler()\n",
        "dftot_standard = scaler.fit_transform(dftotbis)\n",
        "dftot_standard = pd.DataFrame(dftot_standard, index= dftotbis.index, columns=dftotbis.columns)"
      ],
      "metadata": {
        "id": "iedLmZtqhORY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methode du coude pour le tableau avec les clusters pour chaque sport"
      ],
      "metadata": {
        "id": "2PjxMFNKhHft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des données de la dataframe\n",
        "X = dftot_standard.values\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Liste des valeurs de K à tester\n",
        "K = range(1, 10)\n",
        "\n",
        "# Liste des valeurs des variances intra-cluster pour chaque K\n",
        "inertias = []\n",
        "\n",
        "for k in K:\n",
        "    # Créer un modèle de KMeans pour chaque K\n",
        "    model = KMeans(n_clusters=k)\n",
        "\n",
        "    # Ajuster le modèle aux données\n",
        "    model.fit(X)\n",
        "\n",
        "    # Ajouter l'inertie (variance intra-cluster) à la liste\n",
        "    inertias.append(model.inertia_)\n",
        "\n",
        "# Tracer le graphique de la méthode du coude\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('Nombre de clusters (K)')\n",
        "plt.ylabel('Variance intra-cluster')\n",
        "plt.title(\"Méthode du coude pour déterminer le nombre optimal de clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bo8kVPmihH-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering du tableau avec les clusters pour chaque sport\n",
        "\n"
      ],
      "metadata": {
        "id": "BYg6TVHjhIPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisir le nombre de clusters (k)\n",
        "k = 5\n",
        "\n",
        "# Sélectionner les colonnes sur lesquelles faire le clustering\n",
        "cols = [dftot_standard.columns[0],dftot_standard.columns[1]]\n",
        "\n",
        "# Sélectionner les données pour le clustering\n",
        "data = dftot_standard[cols]\n",
        "\n",
        "# Initialiser le modèle de clustering\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Effectuer le clustering\n",
        "kmeans.fit(data)\n",
        "\n",
        "# Ajouter une colonne \"cluster\" à votre tableau de données\n",
        "dftot_standard[\"total_cluster\"] = kmeans.labels_\n",
        "dftotbis[\"total_cluster\"] = kmeans.labels_\n",
        "\n",
        "# Afficher le tableau de données avec la colonne \"cluster\"\n",
        "#df6_standard.head()\n",
        "stats = dftotbis.groupby('total_cluster').agg(['mean', 'median', 'var', 'std'])\n",
        "#stats\n",
        "comptage = dftotbis['total_cluster'].value_counts()\n",
        "comptage"
      ],
      "metadata": {
        "id": "tRW49xm4hIZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export du fichier avec les clusters pour chaque sport"
      ],
      "metadata": {
        "id": "iz05NYwahZ0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dftotbis.to_csv('total_cluster_sans_sorties_mois.csv', index=True)\n",
        "files.download('total_cluster_sans_sorties_mois.csv')"
      ],
      "metadata": {
        "id": "akO1JQrOhaEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}